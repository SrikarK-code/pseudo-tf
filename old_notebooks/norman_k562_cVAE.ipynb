{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "98wyaIenVRVy"
      },
      "source": [
        "\n",
        "\n",
        "### Mount Directory"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "wlFIq2zSCcrx",
        "outputId": "a2d990c7-d022-4a05-ef4a-9c7fd8228499"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Mounted at /content/drive\n"
          ]
        }
      ],
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 2,
      "metadata": {
        "id": "nq17nt0ACxOY"
      },
      "outputs": [],
      "source": [
        "import os"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 3,
      "metadata": {
        "id": "Lk22LUvbCygH"
      },
      "outputs": [],
      "source": [
        "os.chdir('/content/drive/MyDrive/tf design')"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "6RY6YHYjsF1n"
      },
      "source": [
        "### Dataloaders"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 4,
      "metadata": {
        "id": "8ZJ-zQ_-sAo3"
      },
      "outputs": [],
      "source": [
        "import torch\n",
        "import random\n",
        "from collections import defaultdict\n",
        "from torch import nn\n",
        "from torch.nn import functional as F\n",
        "from torch.optim import Adam\n",
        "from torch.optim import lr_scheduler\n",
        "from torch.utils.data import DataLoader, TensorDataset\n",
        "from sklearn.model_selection import train_test_split"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 5,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "nabimZ4gEadt",
        "outputId": "47d395d5-7cd0-459b-b544-f3d31bc62ac1"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Collecting pytorch-lightning\n",
            "  Downloading pytorch_lightning-2.1.2-py3-none-any.whl (776 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m776.9/776.9 kB\u001b[0m \u001b[31m10.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: numpy>=1.17.2 in /usr/local/lib/python3.10/dist-packages (from pytorch-lightning) (1.23.5)\n",
            "Requirement already satisfied: torch>=1.12.0 in /usr/local/lib/python3.10/dist-packages (from pytorch-lightning) (2.1.0+cu118)\n",
            "Requirement already satisfied: tqdm>=4.57.0 in /usr/local/lib/python3.10/dist-packages (from pytorch-lightning) (4.66.1)\n",
            "Requirement already satisfied: PyYAML>=5.4 in /usr/local/lib/python3.10/dist-packages (from pytorch-lightning) (6.0.1)\n",
            "Requirement already satisfied: fsspec[http]>2021.06.0 in /usr/local/lib/python3.10/dist-packages (from pytorch-lightning) (2023.6.0)\n",
            "Collecting torchmetrics>=0.7.0 (from pytorch-lightning)\n",
            "  Downloading torchmetrics-1.2.0-py3-none-any.whl (805 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m805.2/805.2 kB\u001b[0m \u001b[31m47.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: packaging>=20.0 in /usr/local/lib/python3.10/dist-packages (from pytorch-lightning) (23.2)\n",
            "Requirement already satisfied: typing-extensions>=4.0.0 in /usr/local/lib/python3.10/dist-packages (from pytorch-lightning) (4.5.0)\n",
            "Collecting lightning-utilities>=0.8.0 (from pytorch-lightning)\n",
            "  Downloading lightning_utilities-0.10.0-py3-none-any.whl (24 kB)\n",
            "Requirement already satisfied: requests in /usr/local/lib/python3.10/dist-packages (from fsspec[http]>2021.06.0->pytorch-lightning) (2.31.0)\n",
            "Requirement already satisfied: aiohttp!=4.0.0a0,!=4.0.0a1 in /usr/local/lib/python3.10/dist-packages (from fsspec[http]>2021.06.0->pytorch-lightning) (3.8.6)\n",
            "Requirement already satisfied: setuptools in /usr/local/lib/python3.10/dist-packages (from lightning-utilities>=0.8.0->pytorch-lightning) (67.7.2)\n",
            "Requirement already satisfied: filelock in /usr/local/lib/python3.10/dist-packages (from torch>=1.12.0->pytorch-lightning) (3.13.1)\n",
            "Requirement already satisfied: sympy in /usr/local/lib/python3.10/dist-packages (from torch>=1.12.0->pytorch-lightning) (1.12)\n",
            "Requirement already satisfied: networkx in /usr/local/lib/python3.10/dist-packages (from torch>=1.12.0->pytorch-lightning) (3.2.1)\n",
            "Requirement already satisfied: jinja2 in /usr/local/lib/python3.10/dist-packages (from torch>=1.12.0->pytorch-lightning) (3.1.2)\n",
            "Requirement already satisfied: triton==2.1.0 in /usr/local/lib/python3.10/dist-packages (from torch>=1.12.0->pytorch-lightning) (2.1.0)\n",
            "Requirement already satisfied: attrs>=17.3.0 in /usr/local/lib/python3.10/dist-packages (from aiohttp!=4.0.0a0,!=4.0.0a1->fsspec[http]>2021.06.0->pytorch-lightning) (23.1.0)\n",
            "Requirement already satisfied: charset-normalizer<4.0,>=2.0 in /usr/local/lib/python3.10/dist-packages (from aiohttp!=4.0.0a0,!=4.0.0a1->fsspec[http]>2021.06.0->pytorch-lightning) (3.3.2)\n",
            "Requirement already satisfied: multidict<7.0,>=4.5 in /usr/local/lib/python3.10/dist-packages (from aiohttp!=4.0.0a0,!=4.0.0a1->fsspec[http]>2021.06.0->pytorch-lightning) (6.0.4)\n",
            "Requirement already satisfied: async-timeout<5.0,>=4.0.0a3 in /usr/local/lib/python3.10/dist-packages (from aiohttp!=4.0.0a0,!=4.0.0a1->fsspec[http]>2021.06.0->pytorch-lightning) (4.0.3)\n",
            "Requirement already satisfied: yarl<2.0,>=1.0 in /usr/local/lib/python3.10/dist-packages (from aiohttp!=4.0.0a0,!=4.0.0a1->fsspec[http]>2021.06.0->pytorch-lightning) (1.9.2)\n",
            "Requirement already satisfied: frozenlist>=1.1.1 in /usr/local/lib/python3.10/dist-packages (from aiohttp!=4.0.0a0,!=4.0.0a1->fsspec[http]>2021.06.0->pytorch-lightning) (1.4.0)\n",
            "Requirement already satisfied: aiosignal>=1.1.2 in /usr/local/lib/python3.10/dist-packages (from aiohttp!=4.0.0a0,!=4.0.0a1->fsspec[http]>2021.06.0->pytorch-lightning) (1.3.1)\n",
            "Requirement already satisfied: MarkupSafe>=2.0 in /usr/local/lib/python3.10/dist-packages (from jinja2->torch>=1.12.0->pytorch-lightning) (2.1.3)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.10/dist-packages (from requests->fsspec[http]>2021.06.0->pytorch-lightning) (3.4)\n",
            "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.10/dist-packages (from requests->fsspec[http]>2021.06.0->pytorch-lightning) (2.0.7)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.10/dist-packages (from requests->fsspec[http]>2021.06.0->pytorch-lightning) (2023.7.22)\n",
            "Requirement already satisfied: mpmath>=0.19 in /usr/local/lib/python3.10/dist-packages (from sympy->torch>=1.12.0->pytorch-lightning) (1.3.0)\n",
            "Installing collected packages: lightning-utilities, torchmetrics, pytorch-lightning\n",
            "Successfully installed lightning-utilities-0.10.0 pytorch-lightning-2.1.2 torchmetrics-1.2.0\n"
          ]
        }
      ],
      "source": [
        "!pip install pytorch-lightning\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 6,
      "metadata": {
        "id": "BohHOWDpsAo5"
      },
      "outputs": [],
      "source": [
        "import torch\n",
        "from torch.utils.data import DataLoader, random_split\n",
        "import pytorch_lightning as pl\n",
        "\n",
        "def pad_tensor(tensor, max_length, dim=0):\n",
        "    tensor = torch.tensor(tensor) if isinstance(tensor, np.ndarray) else tensor\n",
        "    pad_size = max_length - tensor.shape[dim]\n",
        "    padding = (0, 0) * (tensor.dim() - dim - 1) + (0, pad_size)\n",
        "    return torch.nn.functional.pad(tensor, padding)\n",
        "\n",
        "class CellProteinDataset(torch.utils.data.Dataset):\n",
        "    def __init__(self, joint_embeddings, esm_embeddings):\n",
        "        assert len(joint_embeddings) == len(esm_embeddings), \"Dictionaries must have the same length\"\n",
        "\n",
        "        self.joint_keys = list(joint_embeddings.keys())\n",
        "        self.esm_keys = list(esm_embeddings.keys())\n",
        "\n",
        "        self.joint_embeddings = joint_embeddings\n",
        "        self.esm_embeddings = esm_embeddings\n",
        "\n",
        "        # Compute the maximum embedding size\n",
        "        self.max_joint_dim = max(tensor.shape[0] for tensor in joint_embeddings.values())\n",
        "        self.max_esm_dim = max(tensor.shape[0] for tensor in esm_embeddings.values())\n",
        "\n",
        "    def __len__(self):\n",
        "        return len(self.joint_embeddings)\n",
        "\n",
        "    def __getitem__(self, index):\n",
        "        joint_key = self.joint_keys[index]\n",
        "        esm_key = self.esm_keys[index]\n",
        "\n",
        "        joint_embedding = pad_tensor(self.joint_embeddings[joint_key], self.max_joint_dim)\n",
        "        esm_embedding = pad_tensor(self.esm_embeddings[esm_key], self.max_esm_dim)\n",
        "\n",
        "        return {\n",
        "            \"cell_input\": joint_embedding,\n",
        "            \"protein_input\": esm_embedding\n",
        "        }\n",
        "\n",
        "class CellProteinCollator:\n",
        "    def __call__(self, raw_batch):\n",
        "        batch = {}\n",
        "\n",
        "        cell_input_list = [v['cell_input'] for v in raw_batch]\n",
        "        protein_input_list = [v['protein_input'] for v in raw_batch]\n",
        "\n",
        "        batch['cell_input'] = torch.stack(cell_input_list)\n",
        "        batch['protein_input'] = torch.stack(protein_input_list)\n",
        "\n",
        "        return batch\n",
        "\n",
        "class CellProteinDataModule(pl.LightningDataModule):\n",
        "    def __init__(self, joint_embeddings, esm_embeddings, batch_size):\n",
        "        super().__init__()\n",
        "\n",
        "        dataset = CellProteinDataset(joint_embeddings, esm_embeddings)\n",
        "\n",
        "        # Splitting data into train, test, and validation\n",
        "        train_size = int(0.7 * len(dataset))\n",
        "        val_size = int(0.15 * len(dataset))\n",
        "        test_size = len(dataset) - train_size - val_size\n",
        "\n",
        "        self.train_dataset, self.val_dataset, self.test_dataset = random_split(dataset, [train_size, val_size, test_size])\n",
        "\n",
        "        self.batch_size = batch_size\n",
        "        self.collator = CellProteinCollator()\n",
        "\n",
        "    def train_dataloader(self):\n",
        "        return DataLoader(self.train_dataset, batch_size=self.batch_size, collate_fn=self.collator, shuffle=True,drop_last=True)\n",
        "\n",
        "    def val_dataloader(self):\n",
        "        full_batch = DataLoader(self.val_dataset, batch_size=self.batch_size, collate_fn=self.collator, shuffle=False,drop_last=True)\n",
        "        #binary_batch = DataLoader(self.val_dataset, batch_size=2, collate_fn=self.collator, shuffle=False)\n",
        "        return [full_batch]#, binary_batch]\n",
        "\n",
        "    def test_dataloader(self):\n",
        "        return DataLoader(self.test_dataset, batch_size=self.batch_size, collate_fn=self.collator, shuffle=False,drop_last=True)\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 7,
      "metadata": {
        "id": "yXY6j_BWukFi"
      },
      "outputs": [],
      "source": [
        "import pytorch_lightning as pl\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 8,
      "metadata": {
        "id": "-hjeb7Gmjz5Y"
      },
      "outputs": [],
      "source": [
        "class CellProteinDataModule(pl.LightningDataModule):\n",
        "    def __init__(self, joint_embeddings, esm_embeddings, batch_size, train_keys_list=None, val_test_keys_list=None):\n",
        "        super().__init__()\n",
        "\n",
        "        # Subset dictionaries based on provided keys\n",
        "        train_joint_embeddings = {key: joint_embeddings[key] for key in train_keys_list} if train_keys_list else joint_embeddings\n",
        "        train_esm_embeddings = {key: esm_embeddings[key] for key in train_keys_list} if train_keys_list else esm_embeddings\n",
        "\n",
        "        val_test_joint_embeddings = {key: joint_embeddings[key] for key in val_test_keys_list} if val_test_keys_list else joint_embeddings\n",
        "        val_test_esm_embeddings = {key: esm_embeddings[key] for key in val_test_keys_list} if val_test_keys_list else esm_embeddings\n",
        "\n",
        "        # Create datasets\n",
        "        self.train_dataset = CellProteinDataset(train_joint_embeddings, train_esm_embeddings)\n",
        "        val_test_dataset = CellProteinDataset(val_test_joint_embeddings, val_test_esm_embeddings)\n",
        "\n",
        "        # Splitting val_test_dataset into validation and test sets\n",
        "        val_size = int(0.15 * len(val_test_dataset))\n",
        "        test_size = len(val_test_dataset) - val_size\n",
        "\n",
        "        self.val_dataset, self.test_dataset = random_split(val_test_dataset, [val_size, test_size])\n",
        "\n",
        "        self.batch_size = batch_size\n",
        "        self.collator = CellProteinCollator()\n",
        "\n",
        "    def train_dataloader(self):\n",
        "        return DataLoader(self.train_dataset, batch_size=self.batch_size, collate_fn=self.collator, shuffle=True,drop_last=True)\n",
        "\n",
        "    def val_dataloader(self):\n",
        "        full_batch = DataLoader(self.val_dataset, batch_size=self.batch_size, collate_fn=self.collator, shuffle=False,drop_last=True)\n",
        "        binary_batch = DataLoader(self.val_dataset, batch_size=2, collate_fn=self.collator, shuffle=False)\n",
        "        return [full_batch,binary_batch]\n",
        "\n",
        "    def test_dataloader(self):\n",
        "        return DataLoader(self.test_dataset, batch_size=self.batch_size, collate_fn=self.collator, shuffle=False,drop_last=True)\n",
        "\n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "jAFKJrvuFQ-V"
      },
      "source": [
        "#### load norman19 dataloaders"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 9,
      "metadata": {
        "id": "oAuhwzYG5UWi"
      },
      "outputs": [],
      "source": [
        "import pickle\n",
        "from torch.utils.data import DataLoader\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 10,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "mgiG0m3-0Jaz",
        "outputId": "2116b41e-c3e3-42d6-e1d2-dba61e2c977f"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            " 1010_cvae_gen_v1.csv\n",
            " 1010_cvae_gen_v1.gsheet\n",
            " 1017_cvae_gen_v1.csv\n",
            " 1017_cvae_gen_v1.gsheet\n",
            " 200_perts_subset_df_sequences.csv\n",
            " bmcite_demo.rds\n",
            " bone_marrow_beta_0.0_generated_dict.pkl\n",
            " bone_marrow_beta_0.1_generated_dict.pkl\n",
            " bone_marrow_beta_0.2_generated_dict.pkl\n",
            " bone_marrow_beta_0.3_generated_dict.pkl\n",
            " bone_marrow_beta_0.4_generated_dict.pkl\n",
            " bone_marrow_beta_0.5_generated_dict.pkl\n",
            " bone_marrow_beta_0.6_generated_dict.pkl\n",
            " bone_marrow_beta_0.7_generated_dict.pkl\n",
            " bone_marrow_beta_0.8_generated_dict.pkl\n",
            " bone_marrow_beta_0.9_generated_dict.pkl\n",
            " bone_marrow_beta_1.0_generated_dict.pkl\n",
            " bone_marrow_combon_generation\n",
            " bone_marrow_iteration_090823-attention-beta1_generated_dict.pkl\n",
            " bone_marrow_iteration_092623-attention-beta1_generated_dict.pkl\n",
            " bone_marrow_iteration_092723-ml-beta1_generated_dict.pkl\n",
            " bone_marrow_iteration1_generated_dict.pkl\n",
            " bone_marrow_iteration2_generated_dict.pkl\n",
            " bone_marrow_iteration3_generated_dict_attention_standard.pkl\n",
            " bone_marrow_iteration3_generated_dict_attention_wider.pkl\n",
            " bone_marrow_iteration_82523-attention-beta1_generated_dict.pkl\n",
            " bone_marrow_iteration_82523-regular-beta1_generated_dict.pkl\n",
            " bone_marrow_iteration_82623-attention-beta1-varioussamplingmethods-cosineannealing_generated_dict.pkl\n",
            " bone_marrow_lymphoma_tabula_sapiens.h5ad\n",
            " bulk-gene-activation\n",
            " ckpt-090823-attention-alldata.pt\n",
            " ckpt-090823-attention-fc9-alldata.pt\n",
            " ckpt-092623-attention-alldata.pt\n",
            " ckpt-092623-attention-jointcondition.pt\n",
            " ckpt_100samplepurepredicted.pt\n",
            " ckpt-82323-attention.pt\n",
            " ckpt-82323-beta1-base.pt\n",
            " ckpt-82323.pt\n",
            " ckpt-82523-attention.pt\n",
            " ckpt_gt.pt\n",
            " ckpt_gtTest.pt\n",
            " ckpt-new-architecture-attention-beta-0.02.pt\n",
            " ckpt_predTrain_gtTest.pt\n",
            " ckpt.pt\n",
            " clip-tf-4000\n",
            "'clip-vae-->conditional-tf-gen'\n",
            " combinatorial_optimization_greedy\n",
            " combined_datasets\n",
            " condensed-notebook-gaussian-clip\n",
            " conditions_C1.csv\n",
            " counts.mtx\n",
            " crispr_data\n",
            " cs1_model_7-31\n",
            " cs1_scvi_embedding.npy\n",
            " cs2_matrix_4k.csv\n",
            " cs2_subset_200.csv\n",
            " cVAE-attention82523-architecture\n",
            " cVAE-benchmark\n",
            " data\n",
            " dataloader_params.pkl\n",
            " DATASET_PREP.ipynb\n",
            " diversity_embeddings.pkl\n",
            " essential_all_data_pert_genes.pkl\n",
            " fake2_dict.pkl\n",
            " fake3_dict.pkl\n",
            " fake_dict.pkl\n",
            " features.csv\n",
            " full_protein_data.csv\n",
            " gc_iteration1_generated_dict.pkl\n",
            " GEARS\n",
            " GEARS-prediction-CRISPRa\n",
            " gene2go_all.pkl\n",
            " generateBM1006.pkl\n",
            " generated_dict_newsampling_all.pkl\n",
            " generated_dict_newsampling_noise.pkl\n",
            " generated_dict_newsampling_temp.pkl\n",
            " generated_dict_newsampling_topk.pkl\n",
            " gene_sequences.csv\n",
            " germ_cell_combo_generation\n",
            " gersbach-crisprA\n",
            " glca.txt\n",
            " ground_truth_norman_esm.pkl\n",
            " GSE190604_barcodes.tsv.gz\n",
            " GSE190604_cellranger-guidecalls-aggregated-unfiltered.txt.gz\n",
            " GSE190604_features.tsv.gz\n",
            " GSE190604_matrix.mtx.gz\n",
            " human_germcells.h5ad\n",
            " joint_embedding_c1_c2.npy\n",
            " JointEmbeddingC1TF.ipynb\n",
            " latent1.npy\n",
            " latent1_s22.npy\n",
            " latent1_tian.npy\n",
            " latent2.npy\n",
            " latent_dict_bone_marrow.pkl\n",
            " latent_dict.pkl\n",
            " lightning_logs\n",
            " meta4k.csv\n",
            " metadata.csv\n",
            " model_beta_0.0_epoch0.pt\n",
            " model_beta_0.0_epoch1.pt\n",
            " model_beta_0.0_epoch2.pt\n",
            " model_beta_0.0_epoch3.pt\n",
            " model_beta_0.0_epoch4.pt\n",
            " model_beta_0.0_epoch5.pt\n",
            " model_beta_0.0_epoch6.pt\n",
            " model_beta_0.0_epoch7.pt\n",
            " model_beta_0.0_epoch8.pt\n",
            " model_beta_0.0_epoch9.pt\n",
            " model_beta_0.1_epoch0.pt\n",
            " model_beta_0.1_epoch1.pt\n",
            " model_beta_0.1_epoch2.pt\n",
            " model_beta_0.1_epoch3.pt\n",
            " model_beta_0.1_epoch4.pt\n",
            " model_beta_0.1_epoch5.pt\n",
            " model_beta_0.1_epoch6.pt\n",
            " model_beta_0.1_epoch7.pt\n",
            " model_beta_0.1_epoch8.pt\n",
            " model_beta_0.1_epoch9.pt\n",
            " model_beta_0.2_epoch0.pt\n",
            " model_beta_0.2_epoch1.pt\n",
            " model_beta_0.2_epoch2.pt\n",
            " model_beta_0.2_epoch3.pt\n",
            " model_beta_0.2_epoch4.pt\n",
            " model_beta_0.2_epoch5.pt\n",
            " model_beta_0.2_epoch6.pt\n",
            " model_beta_0.2_epoch7.pt\n",
            " model_beta_0.2_epoch8.pt\n",
            " model_beta_0.2_epoch9.pt\n",
            " model_beta_0.3_epoch0.pt\n",
            " model_beta_0.3_epoch1.pt\n",
            " model_beta_0.3_epoch2.pt\n",
            " model_beta_0.3_epoch3.pt\n",
            " model_beta_0.3_epoch4.pt\n",
            " model_beta_0.3_epoch5.pt\n",
            " model_beta_0.3_epoch6.pt\n",
            " model_beta_0.3_epoch7.pt\n",
            " model_beta_0.3_epoch8.pt\n",
            " model_beta_0.3_epoch9.pt\n",
            " model_beta_0.4_epoch0.pt\n",
            " model_beta_0.4_epoch1.pt\n",
            " model_beta_0.4_epoch2.pt\n",
            " model_beta_0.4_epoch3.pt\n",
            " model_beta_0.4_epoch4.pt\n",
            " model_beta_0.4_epoch5.pt\n",
            " model_beta_0.4_epoch6.pt\n",
            " model_beta_0.4_epoch7.pt\n",
            " model_beta_0.4_epoch8.pt\n",
            " model_beta_0.4_epoch9.pt\n",
            " model_beta_0.5_epoch0.pt\n",
            " model_beta_0.5_epoch1.pt\n",
            " model_beta_0.5_epoch2.pt\n",
            " model_beta_0.5_epoch3.pt\n",
            " model_beta_0.5_epoch4.pt\n",
            " model_beta_0.5_epoch5.pt\n",
            " model_beta_0.5_epoch6.pt\n",
            " model_beta_0.5_epoch7.pt\n",
            " model_beta_0.5_epoch8.pt\n",
            " model_beta_0.5_epoch9.pt\n",
            " model_beta_0.6_epoch0.pt\n",
            " model_beta_0.6_epoch1.pt\n",
            " model_beta_0.6_epoch2.pt\n",
            " model_beta_0.6_epoch3.pt\n",
            " model_beta_0.6_epoch4.pt\n",
            " model_beta_0.6_epoch5.pt\n",
            " model_beta_0.6_epoch6.pt\n",
            " model_beta_0.6_epoch7.pt\n",
            " model_beta_0.6_epoch8.pt\n",
            " model_beta_0.6_epoch9.pt\n",
            " model_beta_0.7_epoch0.pt\n",
            " model_beta_0.7_epoch1.pt\n",
            " model_beta_0.7_epoch2.pt\n",
            " model_beta_0.7_epoch3.pt\n",
            " model_beta_0.7_epoch4.pt\n",
            " model_beta_0.7_epoch5.pt\n",
            " model_beta_0.7_epoch6.pt\n",
            " model_beta_0.7_epoch7.pt\n",
            " model_beta_0.7_epoch8.pt\n",
            " model_beta_0.7_epoch9.pt\n",
            " model_beta_0.8_epoch0.pt\n",
            " model_beta_0.8_epoch1.pt\n",
            " model_beta_0.8_epoch2.pt\n",
            " model_beta_0.8_epoch3.pt\n",
            " model_beta_0.8_epoch4.pt\n",
            " model_beta_0.8_epoch5.pt\n",
            " model_beta_0.8_epoch6.pt\n",
            " model_beta_0.8_epoch7.pt\n",
            " model_beta_0.8_epoch8.pt\n",
            " model_beta_0.8_epoch9.pt\n",
            " model_beta_0.9_epoch0.pt\n",
            " model_beta_0.9_epoch1.pt\n",
            " model_beta_0.9_epoch2.pt\n",
            " model_beta_0.9_epoch3.pt\n",
            " model_beta_0.9_epoch4.pt\n",
            " model_beta_0.9_epoch5.pt\n",
            " model_beta_0.9_epoch6.pt\n",
            " model_beta_0.9_epoch7.pt\n",
            " model_beta_0.9_epoch8.pt\n",
            " model_beta_0.9_epoch9.pt\n",
            " model_beta_1.0_epoch0.pt\n",
            " model_beta_1.0_epoch1.pt\n",
            " model_beta_1.0_epoch2.pt\n",
            " model_beta_1.0_epoch3.pt\n",
            " model_beta_1.0_epoch4.pt\n",
            " model_beta_1.0_epoch5.pt\n",
            " model_beta_1.0_epoch6.pt\n",
            " model_beta_1.0_epoch7.pt\n",
            " model_beta_1.0_epoch8.pt\n",
            " model_beta_1.0_epoch9.pt\n",
            " model_ckpt\n",
            " model.zip\n",
            " new-model\n",
            " norman19c1.h5ad\n",
            " norman19c2.h5ad\n",
            " norman19-groundtruth-embeddings\n",
            " norman-k562-cVAE\n",
            " norman_umi_go\n",
            " norman_umi_go.tar.gz\n",
            " organismal_embeddings.pkl\n",
            " overfit_fix_1_ckpt_100samplepurepredicted.pt\n",
            " overfit_fix_1_gt_pure.pt\n",
            " overfit_fix_1_gtTest.pt\n",
            " overfit_fix_1_predTrain_gtTest.pt\n",
            " overfit_fix_1.pt\n",
            " pca-proteins-esm-2\n",
            " perturbnet2.0\n",
            " prediction_s22_4K_gears.csv\n",
            " predictions_norman_gears.csv\n",
            " predictions_tian_4K_gears.csv\n",
            " predictions_tian_4K_gears.gsheet\n",
            " prediction_tian2021_4K_gears.csv\n",
            " processed_seurat_obj_with_gRNA_data.rds\n",
            " ProtGPT2_1000_random_proteins_20AAchars.csv\n",
            " random_seqs_dict.pkl\n",
            " s22c1.h5ad\n",
            " s22c2.h5ad\n",
            " s22-GEARS+groundtruth---meta-4k-intersection.ipynb\n",
            " s22_gears.h5ad\n",
            " sc22-groundtruth-embeddings\n",
            " scGPT+scBERT\n",
            " sokko-crisprA\n",
            " test_dataset_concat.pkl\n",
            " test_dataset_norman_600.pkl\n",
            " test_dataset_norman_modifiedval.pkl\n",
            " test_dataset_norman.pkl\n",
            " test_dataset_norman_ro.pkl\n",
            " test_dataset_s22.pkl\n",
            " test_dataset_tian.pkl\n",
            " test_model_tian2021\n",
            " tf-code-datapreprocess-code-dump\n",
            " tf_dict.pkl\n",
            " tf_list.csv\n",
            " tf_seqs_dict.pkl\n",
            " tian2021c1.h5ad\n",
            " tian2021c2.h5ad\n",
            " tian2021_pred\n",
            " tian21-groundtruth-embeddings\n",
            "' tian21--jointembedding.ipynb'\n",
            " train_dataset_concat.pkl\n",
            " train_dataset_norman_600.pkl\n",
            " train_dataset_norman_modifiedval.pkl\n",
            " train_dataset_norman.pkl\n",
            " train_dataset_norman_ro.pkl\n",
            " train_dataset_s22.pkl\n",
            " train_dataset_tian.pkl\n",
            " Unipressed\n",
            " VAE-leo-debug\n",
            " val_dataset_concat.pkl\n",
            " val_dataset_norman_600.pkl\n",
            " val_dataset_norman_modifiedval.pkl\n",
            " val_dataset_norman.pkl\n",
            " val_dataset_norman_ro.pkl\n",
            " val_dataset_s22.pkl\n",
            " val_dataset_tian.pkl\n"
          ]
        }
      ],
      "source": [
        "!ls"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 11,
      "metadata": {
        "id": "QY0sqb5N5WrW"
      },
      "outputs": [],
      "source": [
        "with open('train_dataset_norman_ro.pkl', 'rb') as f:\n",
        "    train_dataset_norman = pickle.load(f)\n",
        "\n",
        "with open('val_dataset_norman_ro.pkl', 'rb') as f:\n",
        "    val_dataset_norman = pickle.load(f)\n",
        "\n",
        "with open('test_dataset_norman_ro.pkl', 'rb') as f:\n",
        "    test_dataset_norman = pickle.load(f)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 12,
      "metadata": {
        "id": "TatpfRXFCpxd"
      },
      "outputs": [],
      "source": [
        "from torch.utils.data import Subset\n",
        "train_indices = list(range(30))\n",
        "test_indices = list(range(15))\n",
        "val_indices = list(range(15))\n",
        "\n",
        "# Create subsets\n",
        "train_subset = Subset(train_dataset_norman, train_indices)\n",
        "test_subset = Subset(test_dataset_norman, test_indices)\n",
        "val_subset = Subset(val_dataset_norman, val_indices)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 13,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "IpeCwfCqCRbF",
        "outputId": "fc9ecac7-ccac-4329-82d7-e97e3241d22c"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "30"
            ]
          },
          "metadata": {},
          "execution_count": 13
        }
      ],
      "source": [
        "len(train_subset)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 14,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "yjvz9VD5CZhh",
        "outputId": "7d697da9-8f07-479f-b3e6-ee40649caf86"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "__main__.CellProteinDataset"
            ]
          },
          "metadata": {},
          "execution_count": 14
        }
      ],
      "source": [
        "type(train_dataset_norman)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 15,
      "metadata": {
        "id": "lWxfhFjA5Y8i"
      },
      "outputs": [],
      "source": [
        "with open('dataloader_params.pkl', 'rb') as f:\n",
        "    dataloader_params = pickle.load(f)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 16,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Ccf3eXBgOY-R",
        "outputId": "2721e3eb-ace6-45c0-a462-af668ecc6c2a"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "{'train': {'batch_size': 4, 'shuffle': 'True'},\n",
              " 'val': {'batch_size': 4, 'shuffle': 'False'},\n",
              " 'test': {'batch_size': 4, 'shuffle': 'False'}}"
            ]
          },
          "metadata": {},
          "execution_count": 16
        }
      ],
      "source": [
        "dataloader_params"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 17,
      "metadata": {
        "id": "iQjRaZo15cGX"
      },
      "outputs": [],
      "source": [
        "train_loader_norman = DataLoader(train_subset, **dataloader_params['train'])\n",
        "val_loader_norman = DataLoader(val_subset, **dataloader_params['val'])\n",
        "test_loader_norman = DataLoader(test_subset, **dataloader_params['test'])\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 18,
      "metadata": {
        "id": "W1qHiXCHryXq"
      },
      "outputs": [],
      "source": [
        "from torch.utils.data import Subset"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 19,
      "metadata": {
        "id": "WAldxnKa5hcR"
      },
      "outputs": [],
      "source": [
        "# Converting string 'True'/'False' to boolean\n",
        "dataloader_params['train']['shuffle'] = dataloader_params['train']['shuffle'] == 'True'\n",
        "dataloader_params['val']['shuffle'] = dataloader_params['val']['shuffle'] == 'True'\n",
        "dataloader_params['test']['shuffle'] = dataloader_params['test']['shuffle'] == 'True'\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 20,
      "metadata": {
        "id": "FuI1f0BzzpwN"
      },
      "outputs": [],
      "source": [
        "import numpy as np"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 21,
      "metadata": {
        "id": "vTkaVcdOPxJX"
      },
      "outputs": [],
      "source": [
        "esm_dataset = train_loader_norman.dataset"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 22,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "sx7aBSUYzfLd",
        "outputId": "9bc0ae3b-7b1c-4f5f-e134-e8445cc208ec"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "torch.Size([2078, 1280])"
            ]
          },
          "metadata": {},
          "execution_count": 22
        }
      ],
      "source": [
        "esm_dataset[1]['protein_input'].shape"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 23,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ZNIOaZbX0XBQ",
        "outputId": "1c9b70c9-f4cb-4966-997c-97a9d35d822b"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "{'cell_input': tensor([[-1.5663,  1.1364,  0.6010,  ...,  0.1193, -0.1001,  0.0477],\n",
              "         [-1.3502,  0.4448,  1.6567,  ...,  0.1193, -0.1001,  0.0477],\n",
              "         [ 0.0071,  0.2452, -0.1685,  ...,  0.1193, -0.1001,  0.0477],\n",
              "         ...,\n",
              "         [ 0.0000,  0.0000,  0.0000,  ...,  0.0000,  0.0000,  0.0000],\n",
              "         [ 0.0000,  0.0000,  0.0000,  ...,  0.0000,  0.0000,  0.0000],\n",
              "         [ 0.0000,  0.0000,  0.0000,  ...,  0.0000,  0.0000,  0.0000]]),\n",
              " 'protein_input': tensor([[-0.0160, -0.1942,  0.1267,  ...,  0.0727, -0.1567,  0.1401],\n",
              "         [ 0.0547,  0.1077,  0.1109,  ...,  0.0577,  0.0728,  0.1995],\n",
              "         [ 0.0195,  0.0153,  0.2484,  ..., -0.0064,  0.1929, -0.0309],\n",
              "         ...,\n",
              "         [ 0.0000,  0.0000,  0.0000,  ...,  0.0000,  0.0000,  0.0000],\n",
              "         [ 0.0000,  0.0000,  0.0000,  ...,  0.0000,  0.0000,  0.0000],\n",
              "         [ 0.0000,  0.0000,  0.0000,  ...,  0.0000,  0.0000,  0.0000]])}"
            ]
          },
          "metadata": {},
          "execution_count": 23
        }
      ],
      "source": [
        "esm_dataset[1]"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "cxUFUYpkqYGx"
      },
      "source": [
        "### PCA of train,val,test dataset -- view clusters"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "bJ41QGifJGmB"
      },
      "outputs": [],
      "source": [
        "type(train_dataset_norman)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Qz4mvWVBokUm"
      },
      "outputs": [],
      "source": [
        "import numpy as np\n",
        "import torch\n",
        "from sklearn.decomposition import IncrementalPCA\n",
        "from sklearn.preprocessing import StandardScaler\n",
        "import matplotlib.pyplot as plt\n",
        "\n",
        "# Function to estimate memory usage of a numpy array\n",
        "def estimate_memory_usage(array, unit='bytes'):\n",
        "    memory_bytes = array.nbytes\n",
        "    unit_factor = {'bytes': 1, 'kilobytes': 1024, 'megabytes': 1024**2, 'gigabytes': 1024**3}\n",
        "    return memory_bytes / unit_factor[unit]\n",
        "\n",
        "# Function to retrieve a sample batch from a DataLoader\n",
        "def get_sample_batch(dataloader, key, sample_size=4):\n",
        "    accumulated_data = []\n",
        "    accumulated_size = 0\n",
        "    for batch in dataloader:\n",
        "        # Flatten the data except for the batch dimension\n",
        "        data = batch[key].reshape(batch[key].shape[0], -1).numpy()\n",
        "        accumulated_data.append(data)\n",
        "        accumulated_size += data.shape[0]\n",
        "        if accumulated_size >= sample_size:\n",
        "            break\n",
        "    # Concatenate all collected data and return only the required sample size\n",
        "    accumulated_data = np.concatenate(accumulated_data, axis=0)\n",
        "    return accumulated_data[:sample_size]\n",
        "\n",
        "# Function to perform incremental PCA on a single feature type\n",
        "def incremental_pca(dataloader, feature_key, scaler, ipca, max_batch_size):\n",
        "    for i, batch in enumerate(dataloader):\n",
        "        data = batch[feature_key].reshape(batch[feature_key].shape[0], -1).numpy()\n",
        "        print(f\"Batch {i} size: {data.shape[0]}\")  # Print the size of each batch\n",
        "        if data.shape[0] < 2:\n",
        "            print(f\"Skipping batch {i} because it's smaller than n_components\")\n",
        "            continue  # Skip this batch\n",
        "        for start_idx in range(0, data.shape[0], max_batch_size):\n",
        "            end_idx = start_idx + max_batch_size\n",
        "            batch_data = data[start_idx:end_idx]\n",
        "            batch_data = scaler.transform(batch_data)  # Standardize the features\n",
        "            ipca.partial_fit(batch_data)  # Partial fit on the standardized features\n",
        "\n",
        "\n",
        "# Function to transform features using the fitted scaler and PCA\n",
        "def transform_features(dataloader, feature_key, scaler, ipca, max_batch_size):\n",
        "    transformed_data = []\n",
        "    for batch in dataloader:\n",
        "        data = batch[feature_key].reshape(batch[feature_key].shape[0], -1).numpy()\n",
        "        for start_idx in range(0, data.shape[0], max_batch_size):\n",
        "            end_idx = start_idx + max_batch_size\n",
        "            batch_data = data[start_idx:end_idx]\n",
        "            batch_data = scaler.transform(batch_data)  # Standardize the features\n",
        "            transformed_batch = ipca.transform(batch_data)  # Apply PCA transformation\n",
        "            transformed_data.append(transformed_batch)\n",
        "    return np.concatenate(transformed_data, axis=0)\n",
        "\n",
        "# Get a single batch to estimate memory usage\n",
        "single_batch = next(iter(train_loader_norman))\n",
        "cell_input_sample = single_batch['cell_input'].reshape(single_batch['cell_input'].shape[0], -1).numpy()\n",
        "protein_input_sample = single_batch['protein_input'].reshape(single_batch['protein_input'].shape[0], -1).numpy()\n",
        "\n",
        "# Estimate memory usage for each type of input\n",
        "cell_memory_usage = estimate_memory_usage(cell_input_sample, unit='bytes')\n",
        "protein_memory_usage = estimate_memory_usage(protein_input_sample, unit='bytes')\n",
        "\n",
        "# Define an acceptable memory usage per batch, e.g., 1 GB in a system with 8 GB of RAM\n",
        "acceptable_memory_per_batch = 1 * 1024**3  # in bytes\n",
        "\n",
        "# Calculate the maximum allowable batch size for each input type\n",
        "max_batch_size_cell = acceptable_memory_per_batch // cell_memory_usage\n",
        "max_batch_size_protein = acceptable_memory_per_batch // protein_memory_usage\n",
        "\n",
        "# Choose the smaller batch size to ensure both fit into memory\n",
        "max_batch_size = min(max_batch_size_cell, max_batch_size_protein)\n",
        "\n",
        "# Ensure the max_batch_size is an integer and at least 1\n",
        "max_batch_size = int(max(4, max_batch_size))\n",
        "\n",
        "# Initialize StandardScaler and IncrementalPCA for each input type\n",
        "scaler_cell = StandardScaler()\n",
        "scaler_protein = StandardScaler()\n",
        "ipca_cell = IncrementalPCA(n_components=2)\n",
        "ipca_protein = IncrementalPCA(n_components=2)\n",
        "\n",
        "# Fit the scalers on a sample batch\n",
        "memory_for_scaler_fitting = estimate_memory_usage(single_batch['cell_input'], unit='bytes')\n",
        "sample_size_to_fit_scaler = int(memory_for_scaler_fitting // cell_memory_usage)\n",
        "sample_size_to_fit_scaler = int(max(4, min(sample_size_to_fit_scaler, len(train_loader_norman.dataset))))\n",
        "\n",
        "scaler_cell.fit(get_sample_batch(train_loader_norman, 'cell_input', sample_size_to_fit_scaler))\n",
        "scaler_protein.fit(get_sample_batch(train_loader_norman, 'protein_input', sample_size_to_fit_scaler))\n",
        "\n",
        "# Perform the incremental PCA on the dataloaders for each feature type\n",
        "for dataloader in [train_loader_norman, val_loader_norman, test_loader_norman]:\n",
        "    incremental_pca(dataloader, 'cell_input', scaler_cell, ipca_cell, max_batch_size)\n",
        "    incremental_pca(dataloader, 'protein_input', scaler_protein, ipca_protein, max_batch_size)\n",
        "\n",
        "# Transform features and get the PCA results for plotting\n",
        "transformed_data_cell = transform_features(train_loader_norman, 'cell_input', scaler_cell, ipca_cell, max_batch_size)\n",
        "transformed_data_protein = transform_features(train_loader_norman, 'protein_input', scaler_protein, ipca_protein, max_batch_size)\n",
        "\n",
        "# Plot the PCA results\n",
        "plt.figure(figsize=(8, 6))\n",
        "plt.scatter(transformed_data_cell[:, 0], transformed_data_cell[:, 1], alpha=0.5, label='Cell Input')\n",
        "plt.scatter(transformed_data_protein[:, 0], transformed_data_protein[:, 1], alpha=0.5, label='Protein Input')\n",
        "plt.title('PCA of Cell State and ESM-2 Embeddings')\n",
        "plt.xlabel('Principal Component 1')\n",
        "plt.ylabel('Principal Component 2')\n",
        "plt.legend()\n",
        "plt.show()\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "fkx-pLfPe5xX"
      },
      "outputs": [],
      "source": [
        "# Plot the PCA results\n",
        "plt.figure(figsize=(8, 6))\n",
        "plt.scatter(transformed_data_cell[:, 0], transformed_data_cell[:, 1], alpha=0.5, label='Cell Input')\n",
        "plt.title('PCA of Cell State and ESM-2 Embeddings')\n",
        "plt.xlabel('Principal Component 1')\n",
        "plt.ylabel('Principal Component 2')\n",
        "plt.legend()\n",
        "plt.show()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "mSMa_nOtspjO"
      },
      "outputs": [],
      "source": [
        "total_number_of_samples"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "zDgxF6r5mz4f"
      },
      "source": [
        "### VAE -- cell state condition, outputs protein sequence"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 24,
      "metadata": {
        "id": "fNTaVZk0m9AZ"
      },
      "outputs": [],
      "source": [
        "import numpy as np"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 25,
      "metadata": {
        "id": "qf7niyZ5nEld"
      },
      "outputs": [],
      "source": [
        "def pad_tensor(tensor, max_length, dim=0):\n",
        "    if isinstance(tensor, np.ndarray):\n",
        "        tensor = torch.tensor(tensor)\n",
        "\n",
        "    pad_size = max_length - tensor.shape[dim]\n",
        "    padding = (0, 0) * (tensor.dim() - dim - 1) + (0, pad_size)\n",
        "    return torch.nn.functional.pad(tensor, padding)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 26,
      "metadata": {
        "id": "rtcl8N8tnElf"
      },
      "outputs": [],
      "source": [
        "esm_embedding_dim = 1280\n",
        "joint_embedding_dim = 20"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 27,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "-1DgQn6WnElf",
        "outputId": "12036116-ed96-4026-ae39-6e21b23a72ce"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "1280 20\n"
          ]
        }
      ],
      "source": [
        "print(esm_embedding_dim,joint_embedding_dim)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 28,
      "metadata": {
        "id": "02I_FAK_nElf"
      },
      "outputs": [],
      "source": [
        "### load esm-2 embedding library before generation!!"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 28,
      "metadata": {
        "id": "P6vy1Fh3vRc1"
      },
      "outputs": [],
      "source": []
    },
    {
      "cell_type": "code",
      "execution_count": 29,
      "metadata": {
        "id": "vUb7rwVAvRwk"
      },
      "outputs": [],
      "source": [
        "import pandas as pd\n",
        "from tqdm import tqdm"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 30,
      "metadata": {
        "id": "X60_8oOYvRwl",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "df58114d-5421-47ca-9207-51a38432bccc"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Collecting fair-esm\n",
            "  Downloading fair_esm-2.0.0-py3-none-any.whl (93 kB)\n",
            "\u001b[?25l     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m0.0/93.1 kB\u001b[0m \u001b[31m?\u001b[0m eta \u001b[36m-:--:--\u001b[0m\r\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m93.1/93.1 kB\u001b[0m \u001b[31m2.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hInstalling collected packages: fair-esm\n",
            "Successfully installed fair-esm-2.0.0\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Downloading: \"https://dl.fbaipublicfiles.com/fair-esm/models/esm2_t33_650M_UR50D.pt\" to /root/.cache/torch/hub/checkpoints/esm2_t33_650M_UR50D.pt\n",
            "Downloading: \"https://dl.fbaipublicfiles.com/fair-esm/regression/esm2_t33_650M_UR50D-contact-regression.pt\" to /root/.cache/torch/hub/checkpoints/esm2_t33_650M_UR50D-contact-regression.pt\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "ESM2(\n",
              "  (embed_tokens): Embedding(33, 1280, padding_idx=1)\n",
              "  (layers): ModuleList(\n",
              "    (0-32): 33 x TransformerLayer(\n",
              "      (self_attn): MultiheadAttention(\n",
              "        (k_proj): Linear(in_features=1280, out_features=1280, bias=True)\n",
              "        (v_proj): Linear(in_features=1280, out_features=1280, bias=True)\n",
              "        (q_proj): Linear(in_features=1280, out_features=1280, bias=True)\n",
              "        (out_proj): Linear(in_features=1280, out_features=1280, bias=True)\n",
              "        (rot_emb): RotaryEmbedding()\n",
              "      )\n",
              "      (self_attn_layer_norm): LayerNorm((1280,), eps=1e-05, elementwise_affine=True)\n",
              "      (fc1): Linear(in_features=1280, out_features=5120, bias=True)\n",
              "      (fc2): Linear(in_features=5120, out_features=1280, bias=True)\n",
              "      (final_layer_norm): LayerNorm((1280,), eps=1e-05, elementwise_affine=True)\n",
              "    )\n",
              "  )\n",
              "  (contact_head): ContactPredictionHead(\n",
              "    (regression): Linear(in_features=660, out_features=1, bias=True)\n",
              "    (activation): Sigmoid()\n",
              "  )\n",
              "  (emb_layer_norm_after): LayerNorm((1280,), eps=1e-05, elementwise_affine=True)\n",
              "  (lm_head): RobertaLMHead(\n",
              "    (dense): Linear(in_features=1280, out_features=1280, bias=True)\n",
              "    (layer_norm): LayerNorm((1280,), eps=1e-05, elementwise_affine=True)\n",
              "  )\n",
              ")"
            ]
          },
          "metadata": {},
          "execution_count": 30
        }
      ],
      "source": [
        "!pip install fair-esm\n",
        "##setting up ESM\n",
        "import torch\n",
        "import esm\n",
        "esm_model, alphabet = esm.pretrained.esm2_t33_650M_UR50D()\n",
        "batch_converter = alphabet.get_batch_converter()\n",
        "esm_model.eval()  # disables dropout for deterministic results\n",
        "esm_model.cuda() #push model to gpu"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 31,
      "metadata": {
        "id": "X48WaVdysNi3"
      },
      "outputs": [],
      "source": [
        "# list = list(\"ARNDCEQGHILKMFPSTWYV\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 32,
      "metadata": {
        "id": "zRzQyAN5sOyi"
      },
      "outputs": [],
      "source": [
        "# len(list)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 32,
      "metadata": {
        "id": "O6KjbdIl6IWa"
      },
      "outputs": [],
      "source": []
    },
    {
      "cell_type": "code",
      "execution_count": 33,
      "metadata": {
        "id": "fa8MFD8S7T_J"
      },
      "outputs": [],
      "source": [
        "import torch.nn as nn\n",
        "import torch.nn.functional as F\n",
        "\n",
        "class ReshapeEmbedding(nn.Module):\n",
        "    def __init__(self, from_seq_len, to_seq_len, embed_dim):\n",
        "        super(ReshapeEmbedding, self).__init__()\n",
        "        self.projection = nn.Linear(from_seq_len, to_seq_len)\n",
        "\n",
        "    def forward(self, x):\n",
        "        x = x.permute(0, 2, 1)\n",
        "        x = self.projection(x)\n",
        "        x = x.permute(0, 2, 1)\n",
        "        return x\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "-6ArW22R5wen"
      },
      "source": [
        "### no attn"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "UGGVvrIkk-JJ"
      },
      "outputs": [],
      "source": [
        "\n",
        "class ConditionalVAE(nn.Module):\n",
        "    def __init__(self, esm_model, esm_embedding_dim=1280, hidden_dim=512, latent_dim=256, joint_embedding_dim=20, dropout_rate=0.5, beta=1):\n",
        "        super().__init__()\n",
        "\n",
        "        self.esm_model = esm_model\n",
        "        self.reshaper = ReshapeEmbedding(8350, 2078, joint_embedding_dim)\n",
        "        seq_len = 2078\n",
        "\n",
        "        # Encoder\n",
        "        self.fc_encode1 = nn.Linear(seq_len * (esm_embedding_dim + joint_embedding_dim), hidden_dim)\n",
        "        self.fc_encode1_bn = nn.BatchNorm1d(hidden_dim)\n",
        "        self.fc_encode_mu = nn.Linear(hidden_dim, latent_dim)\n",
        "        self.fc_encode_logvar = nn.Linear(hidden_dim, latent_dim)\n",
        "\n",
        "        # Decoder\n",
        "        self.fc_decode1 = nn.Linear(latent_dim + seq_len * joint_embedding_dim, hidden_dim)\n",
        "        self.fc_decode1_bn = nn.BatchNorm1d(hidden_dim)\n",
        "        self.fc_decode2 = nn.Linear(hidden_dim, seq_len * esm_embedding_dim)\n",
        "\n",
        "        self.dropout = nn.Dropout(dropout_rate)\n",
        "        self.leaky_relu = nn.LeakyReLU(0.1)\n",
        "        self.beta = beta\n",
        "\n",
        "    def encode(self, concatenated_cell_protein_embedding):\n",
        "        h1 = self.leaky_relu(self.fc_encode1(concatenated_cell_protein_embedding))\n",
        "        h1 = self.fc_encode1_bn(h1)\n",
        "        h1 = self.dropout(h1)\n",
        "        return self.fc_encode_mu(h1), self.fc_encode_logvar(h1)\n",
        "\n",
        "    def reparameterize(self, mu, logvar):\n",
        "        std = torch.exp(0.5 * logvar)\n",
        "        eps = torch.randn_like(std)\n",
        "        return mu + eps * std\n",
        "\n",
        "    def decode(self, z, joint_embedding):\n",
        "        z_joint = torch.cat([z, joint_embedding.reshape(joint_embedding.size(0), -1)], dim=1)\n",
        "        h2 = self.leaky_relu(self.fc_decode1(z_joint))\n",
        "        h2 = self.fc_decode1_bn(h2)\n",
        "        h2 = self.dropout(h2)\n",
        "        embeddings = self.fc_decode2(h2)\n",
        "        return embeddings.view(embeddings.size(0), -1, esm_embedding_dim)\n",
        "\n",
        "    def embeddings_to_sequence(self, embeddings):\n",
        "        aa_toks = alphabet.all_toks\n",
        "        aa_idxs = [alphabet.get_idx(aa) for aa in aa_toks]\n",
        "        aa_logits = self.esm_model.lm_head(embeddings)[:, aa_idxs]\n",
        "        predictions = torch.argmax(aa_logits, dim=1).tolist()\n",
        "        generated_peptides = [aa_toks[pred] for pred in predictions]\n",
        "        return generated_peptides\n",
        "\n",
        "    def forward(self, esm_embedding, joint_embedding):\n",
        "        joint_embedding = self.reshaper(joint_embedding)\n",
        "\n",
        "        # Padding esm_embedding to match the sequence length of joint_embedding\n",
        "        pad_size = joint_embedding.size(1) - esm_embedding.size(1)\n",
        "        if pad_size > 0:\n",
        "            padding = torch.zeros((esm_embedding.size(0), pad_size, esm_embedding.size(2)), device=esm_embedding.device)\n",
        "            print(esm_embedding.shape)\n",
        "            esm_embedding = torch.cat([esm_embedding, padding], dim=1)\n",
        "            print(esm_embedding.shape)\n",
        "\n",
        "\n",
        "        concatenated_input = torch.cat([esm_embedding, joint_embedding], dim=2).view(esm_embedding.size(0), -1)\n",
        "        mu, logvar = self.encode(concatenated_input)\n",
        "        z = self.reparameterize(mu, logvar)\n",
        "        reconstructed_protein = self.decode(z, joint_embedding)\n",
        "        return reconstructed_protein, mu, logvar\n",
        "\n",
        "    def loss_function(self, recon_x, x, mu, logvar):\n",
        "        pad_size = recon_x.size(1) - x.size(1)\n",
        "        if pad_size > 0:\n",
        "            padding = torch.zeros((x.size(0), pad_size, x.size(2)), device=x.device)\n",
        "            x = torch.cat([x, padding], dim=1)\n",
        "        MSE = F.mse_loss(recon_x, x)\n",
        "        KLD = -0.5 * torch.sum(1 + logvar - mu.pow(2) - logvar.exp())\n",
        "        return MSE + self.beta * KLD, MSE, KLD\n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Nun1KbLRbW1W"
      },
      "source": [
        "### with attn\n",
        "\n",
        "\n",
        "> num_attention_heads: The number of attention heads.\n",
        "\n",
        "> attention_head_size: The size of each attention head.\n",
        "\n",
        "> attention_dropout_rate: The dropout rate applied to the attention scores.\n",
        "\n",
        "> attention_weight_init_gain: The gain factor used for initializing attention weights."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 34,
      "metadata": {
        "id": "Augh4j3ab3Zy",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "6056797d-e36f-472c-a100-fce421e0ea4f"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "reshaper done...\n",
            "encoder mlp done..\n",
            "attention done...\n",
            "logvar and mu done (encoder)...\n",
            "decoder mlp done...\n",
            "decode linear done...\n",
            "decoder sigmoid done...\n",
            "dropout applied...\n",
            "beta appllied...\n"
          ]
        }
      ],
      "source": [
        "import torch\n",
        "import torch.nn as nn\n",
        "import torch.nn.functional as F\n",
        "import math\n",
        "\n",
        "class LinearBlock(nn.Module):\n",
        "    def __init__(self, input_dim, output_dim):\n",
        "        super(LinearBlock, self).__init__()\n",
        "        self.linear = nn.Linear(input_dim, output_dim)\n",
        "        self.bn = nn.BatchNorm1d(output_dim)\n",
        "        self.relu = nn.ReLU()\n",
        "\n",
        "    def forward(self, x):\n",
        "        print('forward linear')\n",
        "        return self.relu(self.bn(self.linear(x)))\n",
        "\n",
        "class MLP(nn.Module):\n",
        "    def __init__(self, input_dim, hidden_dim, output_dim):\n",
        "        super(MLP, self).__init__()\n",
        "        self.lb1 = LinearBlock(input_dim, hidden_dim)\n",
        "        self.lb2 = LinearBlock(hidden_dim, hidden_dim)\n",
        "        self.lb3 = LinearBlock(hidden_dim, output_dim)\n",
        "\n",
        "    def forward(self, x):\n",
        "        x = self.lb1(x)\n",
        "        x = self.lb2(x)\n",
        "        x = self.lb3(x)\n",
        "        print('forward MLP')\n",
        "        return x\n",
        "\n",
        "class MultiHeadAttention(nn.Module):\n",
        "    def __init__(self, num_heads, hidden_dim, dropout_rate=0.1):\n",
        "        super().__init__()\n",
        "        self.num_heads = num_heads\n",
        "        self.attention_head_size = int(hidden_dim / num_heads)\n",
        "        self.all_head_size = self.num_heads * self.attention_head_size\n",
        "\n",
        "        self.query = nn.Linear(hidden_dim, self.all_head_size)\n",
        "        self.key = nn.Linear(hidden_dim, self.all_head_size)\n",
        "        self.value = nn.Linear(hidden_dim, self.all_head_size)\n",
        "\n",
        "        self.dropout = nn.Dropout(dropout_rate)\n",
        "\n",
        "    def transpose_for_scores(self, x):\n",
        "        new_x_shape = x.size()[:-1] + (self.num_heads, self.attention_head_size)\n",
        "        x = x.view(*new_x_shape)\n",
        "        print(x.shape)\n",
        "        print('transpose done')\n",
        "        return x.permute(0, 2, 1) # changed from 0,2,1,3 to 0,2,1\n",
        "\n",
        "    def forward(self, hidden_states):\n",
        "        mixed_query_layer = self.query(hidden_states)\n",
        "        mixed_key_layer = self.key(hidden_states)\n",
        "        mixed_value_layer = self.value(hidden_states)\n",
        "\n",
        "        query_layer = self.transpose_for_scores(mixed_query_layer)\n",
        "        key_layer = self.transpose_for_scores(mixed_key_layer)\n",
        "        value_layer = self.transpose_for_scores(mixed_value_layer)\n",
        "        print('forward MHA transpose')\n",
        "\n",
        "        attention_scores = torch.matmul(query_layer, key_layer.transpose(-1, -2))\n",
        "        attention_scores = attention_scores / math.sqrt(self.attention_head_size)\n",
        "        attention_probs = nn.Softmax(dim=-1)(attention_scores)\n",
        "        print('attn scores MHA forward')\n",
        "\n",
        "        attention_probs = self.dropout(attention_probs)\n",
        "        print('done dropout MHA')\n",
        "\n",
        "        context_layer = torch.matmul(attention_probs, value_layer)\n",
        "        context_layer = context_layer.permute(0, 2, 1).contiguous() # same permute change here\n",
        "        new_context_layer_shape = context_layer.size()[:-2] + (self.all_head_size,)\n",
        "        context_layer = context_layer.view(*new_context_layer_shape)\n",
        "        print('forward MHA done')\n",
        "        return context_layer\n",
        "\n",
        "class ConditionalVAE(nn.Module):\n",
        "    def __init__(self, esm_model, esm_embedding_dim=1280, hidden_dim=512, latent_dim=256, joint_embedding_dim=20, dropout_rate=0.5, beta=1, num_attention_heads=4):\n",
        "        super().__init__()\n",
        "\n",
        "        self.esm_model = esm_model\n",
        "        self.reshaper = ReshapeEmbedding(8350, 2078, joint_embedding_dim)  # Assuming this class is already defined elsewhere\n",
        "        print('reshaper done...')\n",
        "        seq_len = 2078\n",
        "\n",
        "        # Encoder\n",
        "        self.encoder_mlp = MLP(seq_len * (esm_embedding_dim + joint_embedding_dim), hidden_dim, hidden_dim)\n",
        "        print('encoder mlp done..')\n",
        "        self.attention = MultiHeadAttention(num_attention_heads, hidden_dim, dropout_rate)\n",
        "        print('attention done...')\n",
        "        self.fc_encode_mu = nn.Linear(hidden_dim, latent_dim)\n",
        "        self.fc_encode_logvar = nn.Linear(hidden_dim, latent_dim)\n",
        "        print('logvar and mu done (encoder)...')\n",
        "\n",
        "        # Decoder\n",
        "        self.decoder_mlp = MLP(latent_dim + seq_len * joint_embedding_dim, hidden_dim, hidden_dim)\n",
        "        print('decoder mlp done...')\n",
        "        self.fc_decode2 = nn.Linear(hidden_dim, seq_len * esm_embedding_dim)\n",
        "        print('decode linear done...')\n",
        "        self.sigmoid = nn.Sigmoid()\n",
        "        print('decoder sigmoid done...')\n",
        "        self.dropout = nn.Dropout(dropout_rate)\n",
        "        print('dropout applied...')\n",
        "        self.beta = beta\n",
        "        print('beta appllied...')\n",
        "\n",
        "    def encode(self, concatenated_cell_protein_embedding):\n",
        "        h1 = self.encoder_mlp(concatenated_cell_protein_embedding)\n",
        "        h1 = self.attention(h1)\n",
        "        h1 = self.dropout(h1)\n",
        "        return self.fc_encode_mu(h1), self.fc_encode_logvar(h1)\n",
        "\n",
        "    def reparameterize(self, mu, logvar):\n",
        "        std = torch.exp(0.5 * logvar)\n",
        "        eps = torch.randn_like(std)\n",
        "        return mu + eps * std\n",
        "\n",
        "    def decode(self, z, joint_embedding):\n",
        "        z_joint = torch.cat([z, joint_embedding.reshape(joint_embedding.size(0), -1)], dim=1)\n",
        "        h2 = self.decoder_mlp(z_joint)\n",
        "        h2 = self.dropout(h2)\n",
        "        recon_seq = self.fc_decode2(h2)\n",
        "        recon_seq = self.sigmoid(recon_seq)\n",
        "        return recon_seq.view(recon_seq.size(0), -1, esm_embedding_dim)\n",
        "\n",
        "    def forward(self, esm_embedding, joint_embedding):\n",
        "        # Reshape joint_embedding to match esm_embedding in sequence length\n",
        "        joint_embedding = self.reshaper(joint_embedding)\n",
        "        print('FORWARD RESHAPER DONE...')\n",
        "\n",
        "        # Ensure esm_embedding has the same sequence length as joint_embedding\n",
        "        pad_size = joint_embedding.size(1) - esm_embedding.size(1)\n",
        "        if pad_size > 0:\n",
        "            padding = torch.zeros((esm_embedding.size(0), pad_size, esm_embedding.size(2)), device=esm_embedding.device)\n",
        "            esm_embedding = torch.cat([esm_embedding, padding], dim=1)\n",
        "\n",
        "        # Concatenate embeddings and pass through the encoder to get latent variables\n",
        "        concatenated_input = torch.cat([esm_embedding, joint_embedding], dim=2).flatten(start_dim=1)\n",
        "        print('FORWARD CONCAT DONE...')\n",
        "        mu, logvar = self.encode(concatenated_input)\n",
        "        print('FORWARD ENCODE DONE...')\n",
        "        z = self.reparameterize(mu, logvar)\n",
        "        print('FORWARD REPARAMETERIZE DONE...')\n",
        "\n",
        "        # Decode the latent variable to reconstruct the protein sequence\n",
        "        reconstructed_protein = self.decode(z, joint_embedding)\n",
        "        print('FORWARD DECODE DONE...')\n",
        "        return reconstructed_protein, mu, logvar\n",
        "\n",
        "    def loss_function(self, recon_x, x, mu, logvar):\n",
        "        # Compute reconstruction loss as Mean Squared Error\n",
        "        # Ensure recon_x and x have the same dimensions\n",
        "        if recon_x.size(1) != x.size(1):\n",
        "            min_seq_len = min(recon_x.size(1), x.size(1))\n",
        "            recon_x = recon_x[:, :min_seq_len]\n",
        "            x = x[:, :min_seq_len]\n",
        "        MSE = F.mse_loss(recon_x, x, reduction='sum')\n",
        "        print('mse calculated...')\n",
        "\n",
        "        # Compute Kullback-Leibler Divergence (KLD)\n",
        "        KLD = -0.5 * torch.sum(1 + logvar - mu.pow(2) - logvar.exp())\n",
        "        print('kld calculated...')\n",
        "\n",
        "        # The total loss is the sum of MSE and KLD, with a weighting factor for KLD\n",
        "        print('loss can be outputted...')\n",
        "        return MSE + self.beta * KLD, MSE, KLD\n",
        "\n",
        "\n",
        "# Initialize the model\n",
        "model = ConditionalVAE(\n",
        "    esm_model,\n",
        "    esm_embedding_dim=1280,\n",
        "    hidden_dim=512,\n",
        "    latent_dim=256,\n",
        "    joint_embedding_dim=20,\n",
        "    dropout_rate=0.5,\n",
        "    beta=1,\n",
        "    num_attention_heads=4\n",
        ")\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "IDcDbDT8bZkY"
      },
      "source": [
        "### back to training code"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 35,
      "metadata": {
        "id": "ESbc7RnyeV1V"
      },
      "outputs": [],
      "source": [
        "\n",
        "def init_weights(m):\n",
        "    if isinstance(m, nn.Linear):\n",
        "        torch.nn.init.xavier_uniform_(m.weight)\n",
        "        if m.bias is not None:\n",
        "            m.bias.data.fill_(0.01)\n",
        "\n",
        "learning_rate = 1e-3\n",
        "dropout_rate = 0.5\n",
        "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
        "\n",
        "# model = ConditionalVAE(esm_model, esm_embedding_dim, 512, 256, joint_embedding_dim, dropout_rate).to(device)\n",
        "model.apply(init_weights)\n",
        "\n",
        "optimizer = torch.optim.AdamW(model.parameters(), lr=learning_rate, weight_decay=5e-4)\n",
        "scheduler = torch.optim.lr_scheduler.ReduceLROnPlateau(optimizer, 'min', patience=5, factor=0.5, verbose=True)\n",
        "model = model.to(device)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 36,
      "metadata": {
        "id": "B18Yb3jONWoM"
      },
      "outputs": [],
      "source": [
        "# Training Loop\n",
        "num_epochs = 1\n",
        "accumulation_steps = 10  # Define how many steps to wait before updating the weights\n",
        "\n",
        "train_losses, val_losses, test_losses = [], [], []\n",
        "train_mses, val_mses, test_mses = [], [], []\n",
        "train_klds, val_klds, test_klds = [], [], []"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 37,
      "metadata": {
        "id": "c8qo_4iVFMLS",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "24ebfc4e-e494-4548-e8b1-dcea5a7d0e84"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "torch.Size([2078, 1280])"
            ]
          },
          "metadata": {},
          "execution_count": 37
        }
      ],
      "source": [
        "train_loader_norman.dataset[1]['protein_input'].shape"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "### one batch"
      ],
      "metadata": {
        "id": "9tUWpDzw7QS2"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import torch\n",
        "\n",
        "# Define the function for saving checkpoints\n",
        "def save_checkpoint(state, filename=\"checkpoint.pth.tar\"):\n",
        "    torch.save(state, filename)\n",
        "\n",
        "# Initialize best_val_loss to a very high value\n",
        "best_val_loss = float('inf')\n",
        "\n",
        "# Process one batch from the training set\n",
        "model.train()\n",
        "batch = next(iter(train_loader_norman))\n",
        "print(len(batch))\n",
        "joint_embedding = batch['cell_input'].to(device)\n",
        "esm_embedding = batch['protein_input'].to(device)\n",
        "\n",
        "optimizer.zero_grad()\n",
        "recon_emb, mu, logvar = model(esm_embedding, joint_embedding)\n",
        "loss, MSE, KLD = model.loss_function(recon_emb, esm_embedding, mu, logvar)\n",
        "loss.backward()\n",
        "optimizer.step()\n",
        "\n",
        "train_loss = loss.item()\n",
        "train_mse = MSE.item()\n",
        "train_kld = KLD.item()\n",
        "\n",
        "# Process one batch from the validation set\n",
        "model.eval()\n",
        "batch = next(iter(val_loader_norman))\n",
        "\n",
        "joint_embedding = batch['cell_input'].to(device)\n",
        "esm_embedding = batch['protein_input'].to(device)\n",
        "\n",
        "with torch.no_grad():\n",
        "    recon_emb, mu, logvar = model(esm_embedding, joint_embedding)\n",
        "    loss, MSE, KLD = model.loss_function(recon_emb, esm_embedding, mu, logvar)\n",
        "\n",
        "val_loss = loss.item()\n",
        "val_mse = MSE.item()\n",
        "val_kld = KLD.item()\n",
        "\n",
        "# Scheduler step (if using learning rate scheduler)\n",
        "scheduler.step(val_loss)\n",
        "\n",
        "# Save the model if the validation loss improved\n",
        "if val_loss < best_val_loss:\n",
        "    best_val_loss = val_loss\n",
        "    save_checkpoint({\n",
        "        'state_dict': model.state_dict(),\n",
        "        'optimizer': optimizer.state_dict(),\n",
        "        'scheduler': scheduler.state_dict(),\n",
        "        'best_val_loss': best_val_loss,\n",
        "    }, filename=\"checkpoint_single_batch.pth.tar\")\n",
        "\n",
        "# Process one batch from the test set\n",
        "batch = next(iter(test_loader_norman))\n",
        "\n",
        "joint_embedding = batch['cell_input'].to(device)\n",
        "esm_embedding = batch['protein_input'].to(device)\n",
        "\n",
        "with torch.no_grad():\n",
        "    recon_emb, mu, logvar = model(esm_embedding, joint_embedding)\n",
        "    loss, MSE, KLD = model.loss_function(recon_emb, esm_embedding, mu, logvar)\n",
        "\n",
        "test_loss = loss.item()\n",
        "test_mse = MSE.item()\n",
        "test_kld = KLD.item()\n",
        "\n",
        "# Print Summary\n",
        "print(f'Train Loss: {train_loss:.4f} | Validation Loss: {val_loss:.4f} | Test Loss: {test_loss:.4f}')\n"
      ],
      "metadata": {
        "id": "Jd2SUyu97Rff",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 934
        },
        "outputId": "5ab0737e-9e1f-435f-e5bd-8223e7da9de9"
      },
      "execution_count": 38,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "2\n",
            "FORWARD RESHAPER DONE...\n",
            "FORWARD CONCAT DONE...\n",
            "forward linear\n",
            "forward linear\n",
            "forward linear\n",
            "forward MLP\n",
            "torch.Size([4, 4, 128])\n",
            "transpose done\n",
            "torch.Size([4, 4, 128])\n",
            "transpose done\n",
            "torch.Size([4, 4, 128])\n",
            "transpose done\n",
            "forward MHA transpose\n",
            "attn scores MHA forward\n",
            "done dropout MHA\n",
            "forward MHA done\n",
            "FORWARD ENCODE DONE...\n",
            "FORWARD REPARAMETERIZE DONE...\n",
            "forward linear\n",
            "forward linear\n",
            "forward linear\n",
            "forward MLP\n",
            "FORWARD DECODE DONE...\n",
            "mse calculated...\n",
            "kld calculated...\n",
            "loss can be outputted...\n"
          ]
        },
        {
          "output_type": "error",
          "ename": "OutOfMemoryError",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mOutOfMemoryError\u001b[0m                          Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-38-fa5bf363adb2>\u001b[0m in \u001b[0;36m<cell line: 21>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     19\u001b[0m \u001b[0mloss\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mMSE\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mKLD\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mmodel\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mloss_function\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mrecon_emb\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mesm_embedding\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmu\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlogvar\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     20\u001b[0m \u001b[0mloss\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbackward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 21\u001b[0;31m \u001b[0moptimizer\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mstep\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     22\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     23\u001b[0m \u001b[0mtrain_loss\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mloss\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mitem\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/torch/optim/optimizer.py\u001b[0m in \u001b[0;36mwrapper\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m    371\u001b[0m                             )\n\u001b[1;32m    372\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 373\u001b[0;31m                 \u001b[0mout\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mfunc\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    374\u001b[0m                 \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_optimizer_step_code\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    375\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/torch/optim/optimizer.py\u001b[0m in \u001b[0;36m_use_grad\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m     74\u001b[0m             \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mset_grad_enabled\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdefaults\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'differentiable'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     75\u001b[0m             \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_dynamo\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mgraph_break\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 76\u001b[0;31m             \u001b[0mret\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mfunc\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     77\u001b[0m         \u001b[0;32mfinally\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     78\u001b[0m             \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_dynamo\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mgraph_break\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/torch/optim/adamw.py\u001b[0m in \u001b[0;36mstep\u001b[0;34m(self, closure)\u001b[0m\n\u001b[1;32m    171\u001b[0m             \u001b[0mbeta1\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mbeta2\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mgroup\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m\"betas\"\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    172\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 173\u001b[0;31m             self._init_group(\n\u001b[0m\u001b[1;32m    174\u001b[0m                 \u001b[0mgroup\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    175\u001b[0m                 \u001b[0mparams_with_grad\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/torch/optim/adamw.py\u001b[0m in \u001b[0;36m_init_group\u001b[0;34m(self, group, params_with_grad, grads, amsgrad, exp_avgs, exp_avg_sqs, max_exp_avg_sqs, state_steps)\u001b[0m\n\u001b[1;32m    119\u001b[0m                 )\n\u001b[1;32m    120\u001b[0m                 \u001b[0;31m# Exponential moving average of gradient values\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 121\u001b[0;31m                 state[\"exp_avg\"] = torch.zeros_like(\n\u001b[0m\u001b[1;32m    122\u001b[0m                     \u001b[0mp\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmemory_format\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpreserve_format\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    123\u001b[0m                 )\n",
            "\u001b[0;31mOutOfMemoryError\u001b[0m: CUDA out of memory. Tried to allocate 5.07 GiB. GPU 0 has a total capacty of 39.56 GiB of which 4.94 GiB is free. Process 3669 has 34.62 GiB memory in use. Of the allocated memory 34.02 GiB is allocated by PyTorch, and 111.91 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "### iterate batches"
      ],
      "metadata": {
        "id": "k3O23Wfj7LHQ"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "tj6tfd2JOk9x"
      },
      "outputs": [],
      "source": [
        "import torch\n",
        "\n",
        "# Define the function for saving checkpoints\n",
        "def save_checkpoint(state, filename=\"checkpoint.pth.tar\"):\n",
        "    torch.save(state, filename)\n",
        "\n",
        "# Initialize best_val_loss to a very high value\n",
        "best_val_loss = float('inf')\n",
        "\n",
        "# Training Loop\n",
        "for epoch in range(num_epochs):\n",
        "    # Set model to training mode\n",
        "    model.train()\n",
        "    # Initialize loss accumulators\n",
        "    train_loss, train_mse, train_kld = 0, 0, 0\n",
        "\n",
        "    # Training step\n",
        "    for batch_idx, batch in enumerate(train_loader_norman):\n",
        "        if batch_idx == len(train_loader_norman) - 1:  # Skip the last batch\n",
        "            continue\n",
        "\n",
        "        print(batch_idx)\n",
        "        # Move data to the appropriate device (GPU or CPU)\n",
        "        joint_embedding = batch['cell_input'].to(device)\n",
        "        esm_embedding = batch['protein_input'].to(device)\n",
        "\n",
        "        # Zero the gradients\n",
        "        optimizer.zero_grad()\n",
        "        # Forward pass\n",
        "        recon_emb, mu, logvar = model(esm_embedding, joint_embedding)\n",
        "        # Calculate loss\n",
        "        loss, MSE, KLD = model.loss_function(recon_emb, esm_embedding, mu, logvar)\n",
        "        # Backward pass\n",
        "        loss.backward()\n",
        "\n",
        "        # Gradient accumulation step\n",
        "        if (batch_idx + 1) % accumulation_steps == 0 or batch_idx == len(train_loader_norman) - 2:\n",
        "            optimizer.step()\n",
        "            optimizer.zero_grad()\n",
        "\n",
        "        # Accumulate losses\n",
        "        train_loss += loss.item()\n",
        "        train_mse += MSE.item()\n",
        "        train_kld += KLD.item()\n",
        "\n",
        "    # Calculate average losses for this epoch\n",
        "    train_losses.append(train_loss / len(train_loader_norman.dataset))\n",
        "    train_mses.append(train_mse / len(train_loader_norman.dataset))\n",
        "    train_klds.append(train_kld / len(train_loader_norman.dataset))\n",
        "\n",
        "    # Validation step\n",
        "    model.eval()\n",
        "    val_loss, val_mse, val_kld = 0, 0, 0\n",
        "    with torch.no_grad():\n",
        "        for batch_idx, batch in enumerate(val_loader_norman):\n",
        "            if batch_idx == len(val_loader_norman) - 1:  # Skip the last batch\n",
        "                continue\n",
        "\n",
        "            joint_embedding = batch['cell_input'].to(device)\n",
        "            esm_embedding = batch['protein_input'].to(device)\n",
        "\n",
        "            recon_emb, mu, logvar = model(esm_embedding, joint_embedding)\n",
        "            loss, MSE, KLD = model.loss_function(recon_emb, esm_embedding, mu, logvar)\n",
        "\n",
        "            val_loss += loss.item()\n",
        "            val_mse += MSE.item()\n",
        "            val_kld += KLD.item()\n",
        "\n",
        "    # Scheduler step (if using learning rate scheduler)\n",
        "    scheduler.step(val_loss)\n",
        "\n",
        "    # Save the model if the validation loss improved\n",
        "    if val_loss < best_val_loss:\n",
        "        best_val_loss = val_loss\n",
        "        save_checkpoint({\n",
        "            'epoch': epoch + 1,\n",
        "            'state_dict': model.state_dict(),\n",
        "            'optimizer': optimizer.state_dict(),\n",
        "            'scheduler': scheduler.state_dict(),\n",
        "            'best_val_loss': best_val_loss,\n",
        "        }, filename=f\"checkpoint_epoch_{epoch+1}.pth.tar\")\n",
        "\n",
        "    # Calculate average validation losses for this epoch\n",
        "    val_losses.append(val_loss / len(val_loader_norman.dataset))\n",
        "    val_mses.append(val_mse / len(val_loader_norman.dataset))\n",
        "    val_klds.append(val_kld / len(val_loader_norman.dataset))\n",
        "\n",
        "    # Print Epoch Summary\n",
        "    print(f'Epoch {epoch+1}/{num_epochs} | '\n",
        "          f'Train Loss: {train_losses[-1]:.4f} | '\n",
        "          f'Validation Loss: {val_losses[-1]:.4f}')\n",
        "\n",
        "# After training, evaluate on test set\n",
        "model.eval()\n",
        "test_loss, test_mse, test_kld = 0, 0, 0\n",
        "with torch.no_grad():\n",
        "    for batch_idx, batch in enumerate(test_loader_norman):\n",
        "        if batch_idx == len(test_loader_norman) - 1:  # Skip the last batch\n",
        "            continue\n",
        "\n",
        "        joint_embedding = batch['cell_input'].to(device)\n",
        "        esm_embedding = batch['protein_input'].to(device)\n",
        "\n",
        "        recon_emb, mu, logvar = model(esm_embedding, joint_embedding)\n",
        "        loss, MSE, KLD = model.loss_function(recon_emb, esm_embedding, mu, logvar)\n",
        "\n",
        "        test_loss += loss.item()\n",
        "        test_mse += MSE.item()\n",
        "        test_kld += KLD.item()\n",
        "\n",
        "# Calculate average test losses\n",
        "test_losses.append(test_loss / len(test_loader_norman.dataset))\n",
        "test_mses.append(test_mse / len(test_loader_norman.dataset))\n",
        "test_klds.append(test_kld / len(test_loader_norman.dataset))\n",
        "\n",
        "# Print Test Summary\n",
        "print(f'Test Loss: {test_losses[-1]:.4f} | '\n",
        "      f'Test MSE: {test_mses[-1]:.4f} | '\n",
        "      f'Test KLD: {test_klds[-1]:.4f}')\n"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "### plot loss"
      ],
      "metadata": {
        "id": "qO10EB887S2U"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "r5O1GaTClxyR"
      },
      "outputs": [],
      "source": [
        "import matplotlib.pyplot as plt\n",
        "\n",
        "# Plotting\n",
        "plt.figure(figsize=(15, 5))\n",
        "\n",
        "plt.subplot(1, 3, 1)\n",
        "plt.plot(train_losses, label='Train')\n",
        "plt.plot(val_losses, label='Validation')\n",
        "plt.title('Total Losses')\n",
        "plt.legend()\n",
        "\n",
        "plt.subplot(1, 3, 2)\n",
        "plt.plot(train_mses, label='Train')\n",
        "plt.plot(val_mses, label='Validation')\n",
        "plt.title('MSE Losses')\n",
        "plt.legend()\n",
        "\n",
        "plt.subplot(1, 3, 3)\n",
        "plt.plot(train_klds, label='Train')\n",
        "plt.plot(val_klds, label='Validation')\n",
        "plt.title('KLD Losses')\n",
        "plt.legend()\n",
        "\n",
        "plt.tight_layout()\n",
        "plt.show()\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "CwvHeSxIMq2b"
      },
      "outputs": [],
      "source": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "nNrfPRAIM1_e"
      },
      "source": [
        "#### latent space viz"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "ozdyIfv9M3n6"
      },
      "outputs": [],
      "source": [
        "mu_values = []\n",
        "with torch.no_grad():\n",
        "    for batch in train_loader_norman:\n",
        "        esm_embedding = batch['protein_input'].to(device)\n",
        "        joint_embedding = batch['cell_input'].to(device)\n",
        "\n",
        "        # Reshaping joint_embedding\n",
        "        joint_embedding = model.reshaper(joint_embedding)\n",
        "\n",
        "        # Padding esm_embedding\n",
        "        pad_size = joint_embedding.size(1) - esm_embedding.size(1)\n",
        "        if pad_size > 0:\n",
        "            padding = torch.zeros((esm_embedding.size(0), pad_size, esm_embedding.size(2)), device=esm_embedding.device)\n",
        "            esm_embedding = torch.cat([esm_embedding, padding], dim=1)\n",
        "\n",
        "        # Concatenate the embeddings\n",
        "        concatenated_input = torch.cat([esm_embedding, joint_embedding], dim=2).view(esm_embedding.size(0), -1)\n",
        "\n",
        "        mu, _ = model.encode(concatenated_input)\n",
        "        mu_values.extend(mu.cpu().numpy())\n",
        "\n",
        "mu_values = np.array(mu_values)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "pWb_dfFjM5Bl"
      },
      "outputs": [],
      "source": [
        "from sklearn.decomposition import PCA\n",
        "\n",
        "# Reduce dimensionality to 2D using PCA\n",
        "pca = PCA(n_components=2)\n",
        "mu_2d = pca.fit_transform(mu_values)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "a17HBvhmM6SM"
      },
      "outputs": [],
      "source": [
        "import matplotlib.pyplot as plt\n",
        "\n",
        "plt.scatter(mu_2d[:, 0], mu_2d[:, 1], alpha=0.5)\n",
        "plt.xlabel('PCA 1')\n",
        "plt.ylabel('PCA 2')\n",
        "plt.title('Latent Space Visualization')\n",
        "plt.show()\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "uhBwAKv0M8Nl"
      },
      "outputs": [],
      "source": [
        "from sklearn.manifold import TSNE\n",
        "\n",
        "tsne = TSNE(n_components=2, random_state=0)\n",
        "mu_2d_tsne = tsne.fit_transform(mu_values)\n",
        "\n",
        "plt.scatter(mu_2d_tsne[:, 0], mu_2d_tsne[:, 1], alpha=0.5)\n",
        "plt.xlabel('t-SNE 1')\n",
        "plt.ylabel('t-SNE 2')\n",
        "plt.title('Latent Space Visualization with t-SNE')\n",
        "plt.show()\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "GnRQo2eSStIT"
      },
      "source": [
        "### see how well reconstruction is happening"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "uvzyfIaYTgNg"
      },
      "outputs": [],
      "source": [
        "# Assuming your model instance is named 'model'\n",
        "model.eval()  # Set the model to evaluation mode\n",
        "\n",
        "embeddings_list = []\n",
        "\n",
        "with torch.no_grad():  # Disable gradient computation\n",
        "    for batch in test_loader_norman:\n",
        "        esm_embedding = batch['protein_input'].to(device)\n",
        "        joint_embedding = batch['cell_input'].to(device)\n",
        "\n",
        "        reconstructed_embedding, _, _ = model(esm_embedding, joint_embedding)\n",
        "\n",
        "        embeddings_list.append(reconstructed_embedding.cpu().numpy())\n",
        "\n",
        "# Convert the list of batched embeddings to a single list or array\n",
        "all_embeddings = np.concatenate(embeddings_list, axis=0)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Q_H7-UIQaLWL"
      },
      "outputs": [],
      "source": [
        "def embeddings_to_sequence(embeddings, esm_model, alphabet):\n",
        "    aa_toks = alphabet.all_toks\n",
        "    aa_idxs = [alphabet.get_idx(aa) for aa in aa_toks]\n",
        "    embeddings = embeddings.to(device)\n",
        "    aa_logits = esm_model.lm_head(embeddings)[:, aa_idxs]\n",
        "    predictions = torch.argmax(aa_logits, dim=-1).tolist()\n",
        "    generated_peptides = ''.join([aa_toks[pred] for pred in predictions])  # concatenate the amino acids\n",
        "    return generated_peptides"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "x1-9itSMZzZt"
      },
      "outputs": [],
      "source": [
        "all_decoded_sequences = []\n",
        "\n",
        "# Ensure your model is on the correct device\n",
        "esm_model = esm_model.to(device)\n",
        "\n",
        "# Convert the numpy array to a torch tensor\n",
        "all_embeddings_tensor = torch.tensor(all_embeddings).to(device)\n",
        "\n",
        "# Loop through each sequence in the batch and decode:\n",
        "for idx in range(all_embeddings_tensor.size(0)):\n",
        "    single_embedding = all_embeddings_tensor[idx]  # The embedding is already on the device\n",
        "    decoded_seq = embeddings_to_sequence(single_embedding, esm_model, alphabet)\n",
        "    all_decoded_sequences.append(decoded_seq)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "KWxACFWWaOcF"
      },
      "outputs": [],
      "source": [
        "len(all_decoded_sequences)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "MXONNlXTaUfK"
      },
      "outputs": [],
      "source": [
        "all_decoded_sequences[1]"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "QVmjgJeMalyp"
      },
      "outputs": [],
      "source": [
        "import csv\n",
        "\n",
        "# File path\n",
        "output_path = \"1017_cvae_gen_v1.csv\"\n",
        "\n",
        "# Save to CSV\n",
        "with open(output_path, mode='w', newline='') as file:\n",
        "    writer = csv.writer(file)\n",
        "    writer.writerow([\"AA_Sequence\"])  # Header\n",
        "    for seq in all_decoded_sequences:\n",
        "        writer.writerow([seq])\n",
        "\n",
        "print(f\"Sequences saved to {output_path}\")\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "M4xe_jOQbG4-"
      },
      "source": [
        "### **conditional generation with mlp**"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "MCznPqSHgEkP"
      },
      "outputs": [],
      "source": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "3prU2kxV1ySu"
      },
      "outputs": [],
      "source": [
        "import pickle\n",
        "\n",
        "with open('latent_dict_bone_marrow.pkl', 'rb') as file:\n",
        "    latent_dict = pickle.load(file)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "2s27UNkrIvuz"
      },
      "outputs": [],
      "source": [
        "latent_dict[('lymphocyte',\n",
        "  'dendritic cell')].shape"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "E0Hl3bOxyz6V"
      },
      "outputs": [],
      "source": [
        "### straight generation"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "tx0Tw6R3qkK4"
      },
      "outputs": [],
      "source": [
        "def pad_tensor(tensor, max_length, dim=0):\n",
        "    if isinstance(tensor, np.ndarray):\n",
        "        tensor = torch.tensor(tensor)\n",
        "\n",
        "    pad_size = max_length - tensor.shape[dim]\n",
        "    padding = (0, 0) * (tensor.dim() - dim - 1) + (0, pad_size)\n",
        "    return torch.nn.functional.pad(tensor, padding)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "8GEv4-Ez4QPy"
      },
      "outputs": [],
      "source": [
        "def generate_sequences(model, joint_embedding_tensor, esm_dataset, latent_dim=256, random_sample_size=100):\n",
        "    all_sequences = []\n",
        "\n",
        "    # Ensure the tensor has shape [batch_size, 20]\n",
        "    joint_embedding_tensor = pad_tensor(joint_embedding_tensor, 20, dim=1)\n",
        "    print(joint_embedding_tensor.shape)\n",
        "\n",
        "    for single_joint_embedding in joint_embedding_tensor:\n",
        "        # Randomly sample ESM embeddings\n",
        "        random_indices = torch.randint(0, len(esm_dataset), (random_sample_size,))\n",
        "        random_esm_embeddings = [esm_dataset[i]['protein_input'] for i in random_indices]\n",
        "        random_esm_embeddings = torch.stack(random_esm_embeddings).to(device)\n",
        "\n",
        "        # Repeat the single joint embedding to match the random_sample_size\n",
        "        repeated_joint_embedding = single_joint_embedding.repeat(random_sample_size, 1)\n",
        "\n",
        "        # Transform the repeated joint_embedding\n",
        "        joint_embedding_transformed = model.mlp_transform(repeated_joint_embedding)\n",
        "\n",
        "        # Concatenate the joint embedding with each of the ESM embeddings\n",
        "        concatenated_tensor = torch.cat([random_esm_embeddings, joint_embedding_transformed], dim=1)\n",
        "\n",
        "        # Get the latent space mu\n",
        "        mu, _ = model.encode(concatenated_tensor)\n",
        "\n",
        "        # Decode using the learned latent space\n",
        "        with torch.no_grad():\n",
        "            _, sequences = model.decode(mu, joint_embedding_transformed)\n",
        "\n",
        "        # Collect the sequences for this joint embedding\n",
        "        all_sequences.append(sequences)\n",
        "\n",
        "    return all_sequences\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Yo_Dj13_fewu"
      },
      "outputs": [],
      "source": [
        "esm_dataset = train_loader_norman.dataset"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Dz6V73LUdbnb"
      },
      "outputs": [],
      "source": [
        "generated_dict = {}\n",
        "for key, joint_embedding_tensor in latent_dict.items():\n",
        "    sequences_list = generate_sequences(model, joint_embedding_tensor, esm_dataset, latent_dim=256)\n",
        "    generated_dict[key] = sequences_list\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "V1Kap-fI1VOJ"
      },
      "outputs": [],
      "source": [
        "## write pipeline to where priors are given from GRNboost (sampling -- top 10 TFs are given) -- encode those with the joint embedding OR write seq2seq model"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "8F8GEtPm5UyF"
      },
      "outputs": [],
      "source": [
        "import pickle"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "UY1qdFjZ5DrV"
      },
      "outputs": [],
      "source": [
        "# Serialize and save the dictionary to a .pkl file\n",
        "with open('generateBM1006.pkl', 'wb') as file:\n",
        "    pickle.dump(generated_dict, file)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "-J7dUyc05aYV"
      },
      "outputs": [],
      "source": [
        "# generated_dict checks"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "K1siZJyPy351"
      },
      "outputs": [],
      "source": [
        "print(generated_dict.keys(),len(generated_dict[('lymphocyte', 'common myeloid progenitor')]),type(generated_dict[('lymphocyte', 'common myeloid progenitor')][1]))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "ygyJ8vXU5lLf"
      },
      "outputs": [],
      "source": [
        "len(generated_dict[('lymphocyte', 'megakaryocyte')])"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "CMwfzkUK5lOI"
      },
      "outputs": [],
      "source": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "kYOgAaTQ5lQc"
      },
      "outputs": [],
      "source": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "xnTFJCgB5lSi"
      },
      "outputs": [],
      "source": []
    }
  ],
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "collapsed_sections": [
        "98wyaIenVRVy",
        "cxUFUYpkqYGx",
        "zDgxF6r5mz4f",
        "-6ArW22R5wen",
        "k3O23Wfj7LHQ",
        "qO10EB887S2U",
        "GnRQo2eSStIT",
        "M4xe_jOQbG4-"
      ],
      "machine_shape": "hm",
      "provenance": [],
      "gpuType": "A100"
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}
